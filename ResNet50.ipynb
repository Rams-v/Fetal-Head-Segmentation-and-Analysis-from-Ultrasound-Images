{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11137406,"sourceType":"datasetVersion","datasetId":6946797},{"sourceId":11137521,"sourceType":"datasetVersion","datasetId":6946887}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\nimport pandas as pd\nimport os\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T13:32:22.356866Z","iopub.execute_input":"2025-03-23T13:32:22.357123Z","iopub.status.idle":"2025-03-23T13:32:34.254040Z","shell.execute_reply.started":"2025-03-23T13:32:22.357101Z","shell.execute_reply":"2025-03-23T13:32:34.253367Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Dataset paths\ntrain_dir = \"/kaggle/input/fetal-brain-abnormalities/train\"\nvalid_dir = \"/kaggle/input/fetal-brain-abnormalities/valid\"\ntest_dir = \"/kaggle/input/fetal-brain-abnormalities/test\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T13:32:50.151657Z","iopub.execute_input":"2025-03-23T13:32:50.152006Z","iopub.status.idle":"2025-03-23T13:32:50.155862Z","shell.execute_reply.started":"2025-03-23T13:32:50.151977Z","shell.execute_reply":"2025-03-23T13:32:50.154914Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"train_csv_path = os.path.join(train_dir, \"_classes.csv\")\nvalid_csv_path = os.path.join(valid_dir, \"_classes.csv\")\ntest_csv_path = os.path.join(test_dir, \"_classes.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T13:36:35.260251Z","iopub.execute_input":"2025-03-23T13:36:35.260580Z","iopub.status.idle":"2025-03-23T13:36:35.264332Z","shell.execute_reply.started":"2025-03-23T13:36:35.260558Z","shell.execute_reply":"2025-03-23T13:36:35.263587Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"\n# Load CSV files\ntrain_df = pd.read_csv(train_csv_path)\nvalid_df = pd.read_csv(valid_csv_path)\ntest_df = pd.read_csv(test_csv_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T13:37:11.251708Z","iopub.execute_input":"2025-03-23T13:37:11.252053Z","iopub.status.idle":"2025-03-23T13:37:11.294406Z","shell.execute_reply.started":"2025-03-23T13:37:11.252025Z","shell.execute_reply":"2025-03-23T13:37:11.293794Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Image parameters\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 32","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T13:37:13.424317Z","iopub.execute_input":"2025-03-23T13:37:13.424620Z","iopub.status.idle":"2025-03-23T13:37:13.428283Z","shell.execute_reply.started":"2025-03-23T13:37:13.424597Z","shell.execute_reply":"2025-03-23T13:37:13.427358Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Extract class labels (excluding filename column)\nclass_labels = train_df.columns[1:].tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T13:37:14.466478Z","iopub.execute_input":"2025-03-23T13:37:14.466814Z","iopub.status.idle":"2025-03-23T13:37:14.470271Z","shell.execute_reply.started":"2025-03-23T13:37:14.466786Z","shell.execute_reply":"2025-03-23T13:37:14.469439Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def create_datagen(df, img_dir):\n    datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, rotation_range=20)\n    \n    def generator():\n        for _, row in df.iterrows():\n            img_path = os.path.join(img_dir, row['filename'])\n            img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMG_SIZE)\n            img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n            label = row[class_labels].values.astype(float)\n            yield img_array, label\n    \n    dataset = tf.data.Dataset.from_generator(\n        generator,\n        output_signature=(\n            tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32),\n            tf.TensorSpec(shape=(len(class_labels),), dtype=tf.float32)\n        )\n    )\n    return dataset.batch(BATCH_SIZE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T13:37:24.271371Z","iopub.execute_input":"2025-03-23T13:37:24.271698Z","iopub.status.idle":"2025-03-23T13:37:24.277172Z","shell.execute_reply.started":"2025-03-23T13:37:24.271669Z","shell.execute_reply":"2025-03-23T13:37:24.276327Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_dataset = create_datagen(train_df, train_dir)\nvalid_dataset = create_datagen(valid_df, valid_dir)\ntest_dataset = create_datagen(test_df, test_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T13:37:30.707888Z","iopub.execute_input":"2025-03-23T13:37:30.708214Z","iopub.status.idle":"2025-03-23T13:37:31.551579Z","shell.execute_reply.started":"2025-03-23T13:37:30.708190Z","shell.execute_reply":"2025-03-23T13:37:31.550954Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Load pre-trained ResNet50\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nbase_model.trainable = False  # Freeze base model weights\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T13:37:39.746037Z","iopub.execute_input":"2025-03-23T13:37:39.746355Z","iopub.status.idle":"2025-03-23T13:37:43.065709Z","shell.execute_reply.started":"2025-03-23T13:37:39.746328Z","shell.execute_reply":"2025-03-23T13:37:43.064818Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Custom classification head\nx = GlobalAveragePooling2D()(base_model.output)\nx = Dense(256, activation='relu')(x)\nout = Dense(len(class_labels), activation='sigmoid')(x)  # Sigmoid for multi-label classification","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T13:37:53.868262Z","iopub.execute_input":"2025-03-23T13:37:53.868576Z","iopub.status.idle":"2025-03-23T13:37:53.890588Z","shell.execute_reply.started":"2025-03-23T13:37:53.868547Z","shell.execute_reply":"2025-03-23T13:37:53.889685Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"model = Model(inputs=base_model.input, outputs=out)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T13:37:58.639093Z","iopub.execute_input":"2025-03-23T13:37:58.639412Z","iopub.status.idle":"2025-03-23T13:37:58.651875Z","shell.execute_reply.started":"2025-03-23T13:37:58.639386Z","shell.execute_reply":"2025-03-23T13:37:58.651062Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T13:38:03.807502Z","iopub.execute_input":"2025-03-23T13:38:03.807828Z","iopub.status.idle":"2025-03-23T13:38:03.820644Z","shell.execute_reply.started":"2025-03-23T13:38:03.807799Z","shell.execute_reply":"2025-03-23T13:38:03.819916Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Train the model\nmodel.fit(train_dataset, validation_data=valid_dataset, epochs=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T13:38:10.654413Z","iopub.execute_input":"2025-03-23T13:38:10.654738Z","iopub.status.idle":"2025-03-23T13:39:34.744199Z","shell.execute_reply.started":"2025-03-23T13:38:10.654711Z","shell.execute_reply":"2025-03-23T13:39:34.743238Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n     45/Unknown \u001b[1m24s\u001b[0m 309ms/step - accuracy: 0.1219 - loss: 0.3120","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 457ms/step - accuracy: 0.1226 - loss: 0.3105 - val_accuracy: 0.1839 - val_loss: 0.2068\nEpoch 2/10\n\u001b[1m 1/45\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 178ms/step - accuracy: 0.1562 - loss: 0.2004","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.1638 - loss: 0.2122","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.1639 - loss: 0.2122 - val_accuracy: 0.1782 - val_loss: 0.2055\nEpoch 3/10\n\u001b[1m 1/45\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 183ms/step - accuracy: 0.2188 - loss: 0.1994","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.1721 - loss: 0.2112","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 0.1721 - loss: 0.2112 - val_accuracy: 0.1954 - val_loss: 0.2047\nEpoch 4/10\n\u001b[1m 1/45\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 174ms/step - accuracy: 0.1562 - loss: 0.1990","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.1675 - loss: 0.2104","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 129ms/step - accuracy: 0.1677 - loss: 0.2104 - val_accuracy: 0.2126 - val_loss: 0.2039\nEpoch 5/10\n\u001b[1m 1/45\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 182ms/step - accuracy: 0.1875 - loss: 0.1986","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.1706 - loss: 0.2096","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 129ms/step - accuracy: 0.1708 - loss: 0.2096 - val_accuracy: 0.2356 - val_loss: 0.2031\nEpoch 6/10\n\u001b[1m 1/45\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 172ms/step - accuracy: 0.1875 - loss: 0.1981","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.1787 - loss: 0.2087","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step - accuracy: 0.1788 - loss: 0.2087 - val_accuracy: 0.2414 - val_loss: 0.2024\nEpoch 7/10\n\u001b[1m 1/45\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 171ms/step - accuracy: 0.1562 - loss: 0.1976","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.1873 - loss: 0.2079","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 0.1877 - loss: 0.2078 - val_accuracy: 0.2529 - val_loss: 0.2017\nEpoch 8/10\n\u001b[1m 1/45\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 166ms/step - accuracy: 0.1562 - loss: 0.1971","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.1953 - loss: 0.2070","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 0.1956 - loss: 0.2070 - val_accuracy: 0.2471 - val_loss: 0.2009\nEpoch 9/10\n\u001b[1m 1/45\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 179ms/step - accuracy: 0.1562 - loss: 0.1967","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.2014 - loss: 0.2061","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 127ms/step - accuracy: 0.2017 - loss: 0.2061 - val_accuracy: 0.2471 - val_loss: 0.2002\nEpoch 10/10\n\u001b[1m 1/45\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 168ms/step - accuracy: 0.1562 - loss: 0.1961","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.2145 - loss: 0.2053","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 123ms/step - accuracy: 0.2147 - loss: 0.2053 - val_accuracy: 0.2586 - val_loss: 0.1994\n","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7d4d50579960>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"\n# Evaluate on test set\ntest_loss, test_acc = model.evaluate(test_dataset)\nprint(f\"Test Accuracy: {test_acc * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T13:39:34.745295Z","iopub.execute_input":"2025-03-23T13:39:34.745578Z","iopub.status.idle":"2025-03-23T13:39:38.374160Z","shell.execute_reply.started":"2025-03-23T13:39:34.745556Z","shell.execute_reply":"2025-03-23T13:39:38.373262Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 658ms/step - accuracy: 0.2398 - loss: 0.2047\nTest Accuracy: 21.59%\n","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}